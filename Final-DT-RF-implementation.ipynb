{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ab9c2856776209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T17:46:48.127526Z",
     "start_time": "2024-04-02T17:46:48.113977Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler,OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c60e8-4f9e-416a-b6b9-7638fee97362",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e95008-2ae6-40c8-bc78-cc92118eb66d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T17:46:50.859851Z",
     "start_time": "2024-04-02T17:46:50.832914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:39:21 WARN Utils: Your hostname, DESKTOP-Raveena resolves to a loopback address: 127.0.1.1; using 172.21.63.63 instead (on interface eth0)\n",
      "24/04/02 16:39:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/02 16:39:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "def init_spark():\n",
    "  return SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Big data project\") \\\n",
    "        .config(\"spark.executor.memory\", \"8g\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06f037-4074-4f40-a9bb-ebf231c9d9ee",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f2051b5e45dd36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T17:46:55.063113Z",
     "start_time": "2024-04-02T17:46:53.241469Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "genres_to_keep = [\"action\", \"adventure\", \"horror\", \"crime\", \"romance\", \"thriller\"]\n",
    "dfs=[]\n",
    "for gen in genres_to_keep:\n",
    "    final_df_read_act=spark.read.option(\"header\", \"true\").option(\"multiline\", \"true\").csv(\"data/\"+gen+\".csv\").withColumn(\"genre\",lit(gen)).limit(10000)\n",
    "    dfs.append(final_df_read_act)\n",
    "\n",
    "def unionAll(dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "df = unionAll(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba577095-0bb6-40b6-aad3-7a600543263d",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365022f5af26950b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T17:46:58.831468Z",
     "start_time": "2024-04-02T17:46:58.642617Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id',\n",
       " 'movie_name',\n",
       " 'year',\n",
       " 'genre',\n",
       " 'description',\n",
       " 'director',\n",
       " 'director_id',\n",
       " 'star',\n",
       " 'star_id']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(\"certificate\",\"runtime\",\"rating\",\"votes\",\"gross(in $)\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664f1c57fab4ac7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T17:47:16.648417Z",
     "start_time": "2024-04-02T17:47:02.404679Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def drop_duplicates(train_df):\n",
    "    print(train_df.count())\n",
    "    train_df=train_df.dropDuplicates()\n",
    "    print(train_df.count())\n",
    "    \n",
    "drop_duplicates(df)\n",
    "#drop null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe38188110c0137d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T17:48:10.106425Z",
     "start_time": "2024-04-02T17:48:08.166671Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\", \"true\").csv(\"./final_dataset5_imdb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8798ef4-e32b-4748-8416-0bd5c6f3f7ce",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6218727152a30ee2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data_dataframe(dir=\"final_dataset.csv\"):\n",
    "    csv_directory = dir\n",
    "    final_df_read = spark.read.option(\"header\", \"true\").option(\"multiline\", \"true\").csv(csv_directory)\n",
    "    shuffled_df = final_df_read.withColumn(\"rand\", rand())\n",
    "    shuffled_df = shuffled_df.orderBy(\"rand\")\n",
    "    final_df_read = shuffled_df.drop(\"rand\")\n",
    "    return final_df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f1de8e-725b-4fbb-a5c8-e41091fd3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_distribution(df):\n",
    "    # Group the DataFrame by the \"genre\" column and count the occurrences of each genre\n",
    "    genre_counts = df.groupBy(\"genre\").count()\n",
    "    \n",
    "    # Show the genre counts\n",
    "    genre_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5a6237-6481-49e2-90ff-5d49d10d6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|    genre|count|\n",
      "+---------+-----+\n",
      "|  romance| 9831|\n",
      "|   horror| 9585|\n",
      "|adventure| 9434|\n",
      "|    crime| 9758|\n",
      "| thriller| 9653|\n",
      "|   action| 9494|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df_read=get_data_dataframe(\"final_dataset5_imdb.csv\")\n",
    "# final_df_read.head(5)\n",
    "print_class_distribution(final_df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fc64f5-5032-472f-839b-59ab0be355e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=get_data_dataframe(\"final_dataset5_imdb.csv\").limit(50000)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00e9e84-f366-4390-a3b7-2fa5360dc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_return_mapping_of_index_to_label(df,predicting='genre'):\n",
    "    # Collect distinct pairs of (label, genre)\n",
    "    label_genre_mapping = df.select(\"label\", predicting).distinct().collect()\n",
    "    map={}\n",
    "    # Print the mapping\n",
    "    for mapping in label_genre_mapping:\n",
    "        print(\"Label %s is mapped to genre '%s'\" % (mapping.label, mapping.genre))\n",
    "        map[mapping.label]= mapping.genre\n",
    "    return map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe260538-8efd-4d97-a641-f876640c22fe",
   "metadata": {},
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f0ae290-35d5-4b06-978d-ab3ad2f3d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stages_of_encoding(categoricalColumns =['year',\n",
    "     'description',\n",
    "     'director',\n",
    "     'star'], predicting='genre'):\n",
    "    stages = []\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "        # encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "        stages += [stringIndexer]\n",
    "    label_stringIdx = StringIndexer(inputCol = predicting, outputCol = 'label')\n",
    "    stages += [label_stringIdx]\n",
    "    \n",
    "    assemblerInputs = [c + \"Index\" for c in categoricalColumns] \n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    return stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb88bc21-1d06-4c3b-b0f4-513eb263ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_data(df):\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    pipelineModel = pipeline.fit(df)\n",
    "    final_df_read = pipelineModel.transform(df)\n",
    "    selectedCols = ['label', 'features','genre']+['year',\n",
    "     'description',\n",
    "     'director',\n",
    "     'star']\n",
    "    final_df_read = final_df_read.select(selectedCols)\n",
    "    final_df_read.printSchema()\n",
    "    return final_df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e719112-dc36-472b-a1b1-3610570fe34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- star: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stages=get_stages_of_encoding()\n",
    "final_df_read=get_encoded_data(final_df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe117b95-5428-438d-b7ac-f1a05da713f7",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac39e8a4-92c5-455d-afda-da35421261d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistis(predictions,mapping):\n",
    "\n",
    "    # Compute raw scores on the test set\n",
    "    predictionAndLabels = predictions.rdd.map(lambda lp: (lp.prediction, lp.label))\n",
    "    \n",
    "    # Instantiate metrics object\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision(1.0)\n",
    "    recall = metrics.recall(1.0)\n",
    "    f1Score = metrics.fMeasure(1.0)\n",
    "    total_predictions = confusion_matrix.sum(axis=1)\n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "    \n",
    "    # Statistics by class\n",
    "    labels = predictions.rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "    accuracies = {}\n",
    "    for label in sorted(labels):\n",
    "        print(\"______________________\"+mapping[label]+\"_____________________\")\n",
    "        print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "        print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "        \n",
    "    \n",
    "    # Calculate the accuracy for each label\n",
    "    print(total_predictions)\n",
    "    for label in range(len(total_predictions)):\n",
    "        correct_predictions = confusion_matrix[label, label]\n",
    "        accuracy = correct_predictions / total_predictions[label]\n",
    "        accuracies[label] = accuracy\n",
    "    \n",
    "    # Print accuracies for each label\n",
    "    for label, accuracy in accuracies.items():\n",
    "        print(\"Accuracy for label %s: %s\" % (label, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdc5dd-670b-43f8-81af-fbe1abc7808b",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e025c-432b-400e-9286-6ae7f7ef3b05",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6aeeeea-3e48-4c2e-a9fc-34a8682a64bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:41:57 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count: 46432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:42:00 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "[Stage 128:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set count: 11323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = final_df_read.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Show the number of rows in each set\n",
    "print(\"Training set count:\", train_df.count())\n",
    "print(\"Testing set count:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd7b972-c073-4ff2-93d1-521746ac38b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:42:08 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "24/04/02 16:42:08 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "24/04/02 16:42:09 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 60000 to 46432 (= number of training instances)\n",
      "24/04/02 16:42:09 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "24/04/02 16:42:24 WARN DAGScheduler: Broadcasting large task binary with size 11.6 MiB\n",
      "24/04/02 16:43:00 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "24/04/02 16:43:52 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n",
      "ERROR:root:Exception while sending command.                         (0 + 8) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin123/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin123/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/admin123/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin123/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/admin123/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/admin123/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o437.fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dt \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(featuresCol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, labelCol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, maxBins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m dtModel \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m dtModel\u001b[38;5;241m.\u001b[39mtransform(test_df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# predictions.show(10)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o437.fit"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxBins=60000)\n",
    "dtModel = dt.fit(train_df)\n",
    "predictions = dtModel.transform(test_df)\n",
    "# predictions.show(10)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160a973-c5cb-4b80-9116-242316855078",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp=print_and_return_mapping_of_index_to_label(train_df)\n",
    "print_statistis(predictions,mapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28144e4b-67fe-42bb-9327-8f4198f81c4b",
   "metadata": {},
   "source": [
    "## DT with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e90a3-5f8f-4db0-aeed-97986728f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT with cross validation\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxBins=60000)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "cross_validator = CrossValidator(estimator=dt,\n",
    "                                 estimatorParamMaps=paramGrid,\n",
    "                                 evaluator=evaluator,\n",
    "                                 numFolds=5)\n",
    "\n",
    "cv_model = cross_validator.fit(train_df)\n",
    "predictions = cv_model.transform(test_df)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073e42e-60c6-4284-ab29-7a62f8149d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp=print_and_return_mapping_of_index_to_label(train_df)\n",
    "print_statistis(predictions,mapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14fa82-0a75-4143-81ea-7e21ac8e14df",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f077c-401b-4b23-b831-94779cf331f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",)\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e1aab-c989-4208-a7af-a4b1f9d6cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp=print_and_return_mapping_of_index_to_label(train_df)\n",
    "print_statistis(predictions,mapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e82b8b-401b-4555-832c-9e0bc4b6c23c",
   "metadata": {},
   "source": [
    "## RF with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010429e9-0943-4753-bc59-0434fe1d0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomClassifier with cross validation\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "# pipeline = Pipeline(stages=[stringIndexer, assembler, rf])\n",
    "\n",
    "#the hyperparameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "# cross-validator\n",
    "cross_validator = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\"),\n",
    "                          numFolds=5, seed=42)\n",
    "\n",
    "# model training with the best hyperparameters\n",
    "cv_model = cross_validator.fit(train_df)\n",
    "\n",
    "best_rf_model = cv_model.bestModel.stages[-1]\n",
    "importances = best_rf_model.featureImportances\n",
    "feature_list = ['movie_id',\n",
    " 'movie_name',\n",
    " 'year',\n",
    " 'genre',\n",
    " 'description',\n",
    " 'director',\n",
    " 'director_id',\n",
    " 'star',\n",
    " 'star_id']\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(feature_list, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = cv_model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6293009-c8fb-4b5d-817e-70cfeebd2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp=print_and_return_mapping_of_index_to_label(train_df)\n",
    "print_statistis(predictions,mapp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
