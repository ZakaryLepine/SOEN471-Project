{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d05f44b2-ca7b-495e-b90b-fc5425ac1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import column\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler,OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bd4c8211-f7c2-406f-b538-31cb28e5d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "  return SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Big data project\") \\\n",
    "        .config(\"spark.executor.memory\", \"8g\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8d0afec9-1ab2-4ef0-899a-75dbbf2e0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dataframe(dir=\"final_dataset.csv\"):\n",
    "    # Specify the directory where the CSV files are saved\n",
    "    csv_directory = \"final_dataset.csv\"\n",
    "    \n",
    "    # Read the CSV files back into a DataFrame\n",
    "    final_df_read = spark.read.option(\"header\", \"true\").csv(csv_directory)\n",
    "    \n",
    "    # Add a random column to shuffle data randomly\n",
    "    shuffled_df = final_df_read.withColumn(\"rand\", rand())\n",
    "    shuffled_df = shuffled_df.orderBy(\"rand\")\n",
    "    final_df_read = shuffled_df.drop(\"rand\")\n",
    "    return final_df_read.head(10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c866a22-762b-4cdf-aab3-c67a2a86026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_distribution(df):\n",
    "    # Group the DataFrame by the \"genre\" column and count the occurrences of each genre\n",
    "    genre_counts = df.groupBy(\"genre\").count()\n",
    "    \n",
    "    # Show the genre counts\n",
    "    genre_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c2294-65a4-4cab-9f20-ebb6067b9781",
   "metadata": {},
   "source": [
    "# Replacing Null Values With Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cc3cb1a2-1e27-4365-9b3e-909f10fe4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_null_values_distribution(train_df):\n",
    "    null_value_list = list()\n",
    "    for col_ in train_df.columns:\n",
    "        null_value_list.append(train_df.filter(train_df[col_]==\"\\\\N\").count())                     \n",
    "    plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "    columns = [col_ for col_ in train_df.columns]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(columns, null_value_list, color='skyblue')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Number of Null Values')\n",
    "    plt.ylim(0, train_df.count())\n",
    "    plt.title('Distribution of Null Values in Columns')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484237a5-5ec7-4f5e-9646-028b48bc7623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e3b0c0-90a4-42d1-a4aa-064faf15b830",
   "metadata": {},
   "source": [
    "# Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "52be68e7-8c86-4253-bc9e-d50badc73172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(train_df):\n",
    "    print(train_df.count())\n",
    "    train_df=train_df.dropDuplicates()\n",
    "    print(train_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97169abc-cd30-42ea-b7d9-d1e8373bdb90",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "38abba9c-cfb4-42d8-aef5-92f4f8517812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stages_of_normalization(categoricalColumns =['title',\n",
    "     'director',\n",
    "     'writer',\n",
    "     'actorPrimaryName'], predicting='genre'):\n",
    "    stages = []\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "        # encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "        stages += [stringIndexer]\n",
    "    label_stringIdx = StringIndexer(inputCol = predicting, outputCol = 'label')\n",
    "    stages += [label_stringIdx]\n",
    "    \n",
    "    assemblerInputs = [c + \"Index\" for c in categoricalColumns] \n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    return stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "423b8ff6-7261-4f9b-b38d-4f0da0e9656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_normalized_data(df):\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    pipelineModel = pipeline.fit(df)\n",
    "    final_df_read = pipelineModel.transform(df)\n",
    "    selectedCols = ['label', 'features','genre']+['title',\n",
    "     'director',\n",
    "     'writer',\n",
    "     'actorPrimaryName']\n",
    "    final_df_read = final_df_read.select(selectedCols)\n",
    "    final_df_read.printSchema()\n",
    "    return final_df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fe7ea-5a77-4170-afba-2ac3f0f98718",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "878a1f12-572b-4c05-85ff-66692efc994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_return_mapping_of_index_to_label(df,predicting='genre'):\n",
    "    # Collect distinct pairs of (label, genre)\n",
    "    label_genre_mapping = df.select(\"label\", predicting).distinct().collect()\n",
    "    map={}\n",
    "    # Print the mapping\n",
    "    for mapping in label_genre_mapping:\n",
    "        print(\"Label %s is mapped to genre '%s'\" % (mapping.label, mapping.genre))\n",
    "        map[mapping.label]= mapping.genre\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aacf4e-86e6-4e8b-add2-fd96280f3062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0a7dac7c-4234-4c90-8a64-c82badcae34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 2.0 is mapped to genre 'Action'\n",
      "Label 5.0 is mapped to genre 'Romance'\n",
      "Label 1.0 is mapped to genre 'Comedy'\n",
      "Label 0.0 is mapped to genre 'Drama'\n",
      "Label 4.0 is mapped to genre 'Thriller'\n",
      "Label 3.0 is mapped to genre 'Horror'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2.0: 'Action',\n",
       " 5.0: 'Romance',\n",
       " 1.0: 'Comedy',\n",
       " 0.0: 'Drama',\n",
       " 4.0: 'Thriller',\n",
       " 3.0: 'Horror'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_and_return_mapping_of_index_to_label(final_df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bc5cd-b4b1-4933-9ffd-29849c7855e4",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0601470a-e89b-429f-93a2-4cd8d19701dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/20 16:07:44 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count: 63052\n",
      "Testing set count: 15495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/20 16:07:45 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = final_df_read.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Show the number of rows in each set\n",
    "print(\"Training set count:\", train_df.count())\n",
    "print(\"Testing set count:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06162ff6-99a3-4707-9514-68971742361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/20 16:07:45 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/03/20 16:07:46 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/03/20 16:07:46 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/03/20 16:07:54 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/03/20 16:08:02 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/03/20 16:08:11 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "24/03/20 16:08:28 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label',maxBins=60000)\n",
    "dtModel = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "914f1970-c394-41c4-9183-cbc826e2860b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----+-------+--------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|genre|  title|            director|            writer|    actorPrimaryName|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-----+-------+--------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[6.0,3157.0,2194....|Drama| Escape|      Victor Bojinov|    Delyana Maneva|       Hristo Petkov|[9406.0,6620.0,21...|[0.42624733765350...|       0.0|\n",
      "|  0.0|[11.0,189.0,155.0...|Drama|Goliath|  Adilkhan Yerzhanov|Adilkhan Yerzhanov|    Daniyar Alshinov|[390.0,70.0,90.0,...|[0.64462809917355...|       0.0|\n",
      "|  0.0|[11.0,623.0,5627....|Drama|Goliath|    Frédéric Tellier|     Gaëlle Bellan|     Laurent Stocker|[19.0,120.0,259.0...|[0.04059829059829...|       2.0|\n",
      "|  0.0|[22.0,2756.0,2530...|Drama|   Vera|    Nedeljko Kovacic| Kristina Djukovic|     Nebojsa Dugalic|[390.0,70.0,90.0,...|[0.64462809917355...|       0.0|\n",
      "|  0.0|[22.0,8526.0,8689...|Drama|   Vera|     Steffy Argelich|   Steffy Argelich|María Jose Gil Go...|[390.0,70.0,90.0,...|[0.64462809917355...|       0.0|\n",
      "|  0.0|[23.0,1317.0,1202...|Drama|  Bluff|    Sheikh Shahnawaz|  Sheikh Shahnawaz|      Corey Thompson|[390.0,70.0,90.0,...|[0.64462809917355...|       0.0|\n",
      "|  0.0|[25.0,1262.0,1142...|Drama|Breathe|        Onur Karaman|      Onur Karaman|      Vincent Fafard|[751.0,440.0,256....|[0.35391140433553...|       0.0|\n",
      "|  0.0|[36.0,643.0,588.0...|Drama|Centaur|      Kirill Kemnits|     Mikhail Zubko|         Oleg Evteev|[4563.0,2148.0,67...|[0.47002472187886...|       0.0|\n",
      "|  0.0|[55.0,3366.0,3310...|Drama|  Karma|    Anthony Williams|  Anthony Williams|Damien Thomas Howard|[390.0,70.0,90.0,...|[0.64462809917355...|       0.0|\n",
      "|  0.0|[58.0,3642.0,3923...|Drama|  Medal|Dhaval Jitesh Shukal|        Jay Master|        Shounak Vyas|[1022.0,885.0,612...|[0.31670281995661...|       0.0|\n",
      "+-----+--------------------+-----+-------+--------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/20 16:09:01 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n"
     ]
    }
   ],
   "source": [
    "predictions = dtModel.transform(test_df)\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50abed-d065-4a18-8c92-df277735ab6f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "15008c51-8730-45c5-94cf-1595a501237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/20 16:09:01 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def print_statistis(predictions,mapping):\n",
    "\n",
    "    # Compute raw scores on the test set\n",
    "    predictionAndLabels = predictions.rdd.map(lambda lp: (lp.prediction, lp.label))\n",
    "    \n",
    "    # Instantiate metrics object\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision(1.0)\n",
    "    recall = metrics.recall(1.0)\n",
    "    f1Score = metrics.fMeasure(1.0)\n",
    "    total_predictions = confusion_matrix.sum(axis=1)\n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "    \n",
    "    # Statistics by class\n",
    "    labels = predictions.rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "    accuracies = {}\n",
    "    for label in sorted(labels):\n",
    "        print(\"______________________\"+mapping[label]+\"_____________________\")\n",
    "        print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "        print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "        correct_predictions = confusion_matrix[label, label]\n",
    "        accuracy = correct_predictions / total_predictions[label]\n",
    "        print(\"Accuracy for label %s: %s\" % (label, accuracy))\n",
    "    \n",
    "    # # Calculate the accuracy for each label\n",
    "   \n",
    "    # print(total_predictions)\n",
    "    # for label in range(len(total_predictions)):\n",
    "    #     correct_predictions = confusion_matrix[label, label]\n",
    "    #     accuracy = correct_predictions / total_predictions[label]\n",
    "    #     accuracies[label] = accuracy\n",
    "    \n",
    "    # # Print accuracies for each label\n",
    "    # for label, accuracy in accuracies.items():\n",
    "        \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "10d4b124-98df-41fb-8efc-5fa083ef3a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3d27693c-f564-449d-a4f9-60ec6931a64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umang/.local/lib/python3.10/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "24/03/20 16:54:53 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "24/03/20 16:54:54 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "24/03/20 16:56:21 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Stats\n",
      "Precision = 0.41846323935876173\n",
      "Recall = 0.17592377411108528\n",
      "F1 Score = 0.2477094240837696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 712:================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 precision = 0.4130849220103986\n",
      "Class 0.0 recall = 0.811404255319149\n",
      "Class 0.0 F1 Measure = 0.5474590869939707\n",
      "Class 1.0 precision = 0.41846323935876173\n",
      "Class 1.0 recall = 0.17592377411108528\n",
      "Class 1.0 F1 Measure = 0.2477094240837696\n",
      "Class 2.0 precision = 0.35239423523942354\n",
      "Class 2.0 recall = 0.30626262626262624\n",
      "Class 2.0 F1 Measure = 0.32771292693471676\n",
      "Class 3.0 precision = 0.0\n",
      "Class 3.0 recall = 0.0\n",
      "Class 3.0 F1 Measure = 0.0\n",
      "Class 4.0 precision = 0.0\n",
      "Class 4.0 recall = 0.0\n",
      "Class 4.0 F1 Measure = 0.0\n",
      "Class 5.0 precision = 0.0\n",
      "Class 5.0 recall = 0.0\n",
      "Class 5.0 F1 Measure = 0.0\n",
      "[5875. 4303. 2475. 1458. 1090.  299.]\n",
      "Accuracy for label 0: 0.811404255319149\n",
      "Accuracy for label 1: 0.17592377411108528\n",
      "Accuracy for label 2: 0.30626262626262624\n",
      "Accuracy for label 3: 0.0\n",
      "Accuracy for label 4: 0.0\n",
      "Accuracy for label 5: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print_statistis(predictions,print_and_return_mapping_of_index_to_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1e0d23ab-e52b-47ad-b191-cd6361dae97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label 0: 0.811404255319149\n",
      "Accuracy for label 1: 0.17592377411108528\n",
      "Accuracy for label 2: 0.30626262626262624\n",
      "Accuracy for label 3: 0.0\n",
      "Accuracy for label 4: 0.0\n",
      "Accuracy for label 5: 0.0\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
